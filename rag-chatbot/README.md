# ğŸ“„ RAG Chatbot â€” PDF Question Answering System

A production-ready Retrieval-Augmented Generation (RAG) chatbot that lets you upload PDFs and ask questions about their content. Built with LangChain, ChromaDB, and OpenAI.

---

## ğŸ¯ What It Does

Upload any PDF â†’ ask questions in natural language â†’ get accurate answers grounded in your documents with source citations.

**Example:**
```
ğŸ“„ Uploaded: company_policy.pdf
ğŸ§‘ Q: "What is the leave policy for new employees?"
ğŸ¤– A: "New employees are entitled to 15 days of paid leave per year,
       accruing at 1.25 days per month..."
ğŸ“š Source: Page 12, Chunk 3
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PDF Upload  â”‚â”€â”€â”€â”€â–¶â”‚  Text Extraction â”‚â”€â”€â”€â”€â–¶â”‚   Chunking   â”‚
â”‚  (PyPDF)     â”‚     â”‚  (page by page)  â”‚     â”‚  (500 chars) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                      â”‚
                                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Answer     â”‚â—€â”€â”€â”€â”€â”‚   LLM (GPT-3.5) â”‚â—€â”€â”€â”€â”€â”‚  ChromaDB    â”‚
â”‚  + Sources   â”‚     â”‚ Context + Query  â”‚     â”‚  (Vectors)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                      â–²
                                                      â”‚
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
                                              â”‚  User Query  â”‚
                                              â”‚  (Embedding) â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**RAG Pipeline Steps:**
1. **Load** â€” PDF pages extracted via PyPDFLoader
2. **Chunk** â€” Text split into 500-char overlapping chunks using RecursiveCharacterTextSplitter
3. **Embed** â€” Each chunk converted to vector embedding (OpenAI text-embedding-ada-002)
4. **Store** â€” Vectors indexed in ChromaDB for fast similarity search
5. **Retrieve** â€” User query embedded â†’ top-4 similar chunks found via cosine similarity
6. **Generate** â€” Retrieved chunks + query + chat history sent to GPT-3.5-turbo â†’ answer generated

---

## ğŸ› ï¸ Tech Stack

| Component       | Technology              | Why                                  |
|-----------------|-------------------------|--------------------------------------|
| Framework       | LangChain               | Modular RAG pipeline orchestration   |
| Vector Store    | ChromaDB                | Lightweight, no setup needed         |
| LLM             | OpenAI GPT-3.5-turbo    | Fast, cost-effective generation      |
| Embeddings      | OpenAI Ada-002          | High-quality text embeddings         |
| PDF Parsing     | PyPDF                   | Reliable PDF text extraction         |
| UI              | Streamlit               | Rapid prototyping, built-in chat UI  |
| Memory          | ConversationBufferWindow| Maintains last 5 turns for follow-ups|

---

## ğŸš€ Quick Start

### 1. Clone the repo
```bash
git clone https://github.com/YOUR_USERNAME/ai-agents-portfolio.git
cd ai-agents-portfolio/01-rag-chatbot
```

### 2. Create virtual environment
```bash
python -m venv venv
source venv/bin/activate        # Mac/Linux
# venv\Scripts\activate         # Windows
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Set up environment variables
```bash
cp .env.example .env
# Edit .env and add your OpenAI API key
```

### 5. Run the app
```bash
streamlit run app.py
```

### 6. Test without UI (optional)
```bash
# Put a sample PDF in data/ folder first
python rag_engine.py
```

---

## ğŸ“ Project Structure

```
01-rag-chatbot/
â”œâ”€â”€ rag_engine.py       # Core RAG pipeline (load, chunk, embed, retrieve, generate)
â”œâ”€â”€ app.py              # Streamlit chat interface
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ .env.example        # Environment variable template
â”œâ”€â”€ .gitignore
â”œâ”€â”€ data/               # Sample PDFs (for testing)
â”œâ”€â”€ screenshots/        # Demo screenshots
â””â”€â”€ README.md
```

---

## âœ¨ Key Features

- **Multi-PDF Support** â€” Upload and query across multiple documents simultaneously
- **Source Citations** â€” Every answer shows which chunks and pages were used
- **Chat Memory** â€” Remembers last 5 conversations for follow-up questions
- **Chunk Overlap** â€” 50-char overlap prevents context loss at chunk boundaries
- **Similarity Search** â€” Top-4 most relevant chunks retrieved per query

---

## ğŸ”§ Configuration

You can tune these parameters in `rag_engine.py`:

| Parameter        | Default | What it controls                          |
|------------------|---------|-------------------------------------------|
| `chunk_size`     | 500     | Characters per chunk (smaller = precise)  |
| `chunk_overlap`  | 50      | Overlap between chunks (prevents cutoffs) |
| `k` (retriever)  | 4       | Number of chunks retrieved per query      |
| `k` (memory)     | 5       | Number of past conversations remembered   |
| `temperature`    | 0       | LLM randomness (0 = deterministic)        |

---

## ğŸ”® Future Improvements

- [ ] Add support for DOCX, TXT, and web URLs
- [ ] Implement hybrid search (keyword + semantic)
- [ ] Add re-ranking with cross-encoder for better retrieval
- [ ] Deploy on Hugging Face Spaces / Streamlit Cloud
- [ ] Add evaluation metrics (retrieval accuracy, answer faithfulness)
- [ ] Upgrade to Agentic RAG with LangGraph (see `02-agentic-rag/`)

---

## ğŸ“ What I Learned

- How **text embeddings** capture semantic meaning and enable similarity search
- The importance of **chunk size and overlap** in retrieval quality
- How **ConversationalRetrievalChain** maintains context across multi-turn conversations
- Trade-offs between **retrieval precision vs recall** when tuning `k` parameter
- Why **source attribution** matters for trustworthy AI applications

---

## ğŸ“„ License

MIT
